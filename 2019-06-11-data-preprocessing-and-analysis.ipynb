{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    USING_IPYTHON = True\n",
    "except NameError:\n",
    "    USING_IPYTHON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('mrp_data_dir', help='')\n",
    "ap.add_argument('--train-sub-dir', default='training', help='')\n",
    "ap.add_argument('--companion-sub-dir', default='./mrp-companion/2019/companion')\n",
    "ap.add_argument('--mrp-file-extension', default='.mrp')\n",
    "ap.add_argument('--companion-file-extension', default='.conllu')\n",
    "arg_string = \"\"\"\n",
    "    ./data/\n",
    "\"\"\"\n",
    "arguments = [arg for arg_line in arg_string.split(r'\\\\n') for arg in arg_line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    args = ap.parse_args(arguments)\n",
    "else:\n",
    "    args = ap.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(companion_file_extension='.conllu', companion_sub_dir='./mrp-companion/2019/companion', mrp_data_dir='./data/', mrp_file_extension='.mrp', train_sub_dir='training')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ipython notebook specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    # matplotlib config\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKWOWN = 'UNKWOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ucca', 'psd', 'eds', 'dm', 'amr']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(args.mrp_data_dir, args.train_sub_dir)\n",
    "frameworks = [sub_dir for sub_dir in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, sub_dir))]\n",
    "frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frameworks:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "dataset_name:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  50%|█████     | 1/2 [00:00<00:00,  3.93it/s]\u001b[A\n",
      "frameworks:  20%|██        | 1/5 [00:00<00:02,  1.56it/s]s]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  40%|████      | 2/5 [00:04<00:05,  1.70s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  60%|██████    | 3/5 [00:11<00:06,  3.10s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  80%|████████  | 4/5 [00:18<00:04,  4.22s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  43%|████▎     | 6/14 [00:00<00:00, 21.87it/s]\u001b[A\n",
      "dataset_name:  57%|█████▋    | 8/14 [00:00<00:00, 18.54it/s]\u001b[A\n",
      "dataset_name:  71%|███████▏  | 10/14 [00:01<00:00,  6.65it/s]\u001b[A\n",
      "dataset_name:  79%|███████▊  | 11/14 [00:01<00:00,  6.02it/s]\u001b[A\n",
      "frameworks: 100%|██████████| 5/5 [00:19<00:00,  3.39s/it]t/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons = {}\n",
    "for framework in tqdm(frameworks, desc='frameworks'):\n",
    "    dataset2mrp_jsons = {}\n",
    "    framework_dir = os.path.join(train_dir, framework)\n",
    "    dataset_names = os.listdir(framework_dir)\n",
    "    \n",
    "    for dataset_name in tqdm(dataset_names, desc='dataset_name'):\n",
    "        mrp_jsons = []\n",
    "        if not dataset_name.endswith(args.mrp_file_extension):\n",
    "            continue\n",
    "        with open(os.path.join(framework_dir, dataset_name)) as rf:\n",
    "            for line in rf:\n",
    "                mrp_json = json.loads(line.strip())\n",
    "                if framework == 'ucca' and 'nodes' in mrp_json and 'input' in mrp_json:\n",
    "                    input_text = mrp_json['input']\n",
    "                    nodes = mrp_json['nodes']\n",
    "                    for i, node in enumerate(nodes):\n",
    "                        if 'anchors' not in node:\n",
    "                            continue\n",
    "                        text_segments = []\n",
    "                        for anchor in node['anchors']:\n",
    "                            text_segments.append(input_text[anchor.get('from', -1): anchor.get('to', -1)])\n",
    "                        mrp_json['nodes'][i]['label'] = ''.join(text_segments)\n",
    "                        \n",
    "                mrp_jsons.append(mrp_json)\n",
    "        dataset_name = dataset_name.split('.')[0]\n",
    "        dataset2mrp_jsons[dataset_name] = mrp_jsons\n",
    "                \n",
    "    framework2dataset2mrp_jsons[framework] = dataset2mrp_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:ucca\n",
      "INFO:__main__:['wiki', 'ewt']\n",
      "INFO:__main__:psd\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:eds\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:dm\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:amr\n",
      "INFO:__main__:['xinhua', 'wsj', 'wiki', 'wb', 'rte', 'proxy', 'mt09sdl', 'lorelei', 'fables', 'dfb', 'dfa', 'cctv', 'bolt', 'amr-guidelines']\n"
     ]
    }
   ],
   "source": [
    "for framework in framework2dataset2mrp_jsons:\n",
    "    logger.info(framework)\n",
    "    logger.info(list(framework2dataset2mrp_jsons[framework].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing companion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset: 100%|██████████| 13/13 [00:01<00:00,  6.88it/s]\n",
      "dataset: 100%|██████████| 5/5 [00:04<00:00,  1.05s/it]\n",
      "dataset: 100%|██████████| 6/6 [00:00<00:00, 22.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset2cid2parse = {}\n",
    "for framework in os.listdir(args.companion_sub_dir):\n",
    "    framework_dir = os.path.join(args.companion_sub_dir, framework)\n",
    "    if not os.path.isdir(framework_dir):\n",
    "        continue\n",
    "    for dataset in tqdm(os.listdir(framework_dir), desc='dataset'):\n",
    "        if not dataset.endswith(args.companion_file_extension):\n",
    "            continue\n",
    "        dataset_name = dataset.split('.')[0].rstrip(string.digits)\n",
    "        cid2parse = {}\n",
    "        with open(os.path.join(framework_dir, dataset)) as rf:\n",
    "            parse = []\n",
    "            for line in rf:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    cid2parse[cid] = parse\n",
    "                    parse = []\n",
    "                    cid = ''\n",
    "                elif line.startswith('#'):\n",
    "                    cid = line[1:]\n",
    "                else:\n",
    "                    parse.append(line.split('\\t'))\n",
    "        dataset2cid2parse[dataset_name] = cid2parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['amr-guidelines', 'bolt', 'cctv', 'dfa', 'dfb', 'fables', 'lorelei', 'mt09sdl', 'proxy', 'rte', 'wb', 'wiki', 'xinhua', 'wsj', 'ewt'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2cid2parse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'According',\n",
       "  'accord',\n",
       "  'VERB',\n",
       "  'VBG',\n",
       "  '_',\n",
       "  '10',\n",
       "  'case',\n",
       "  '_',\n",
       "  'TokenRange=0:9'],\n",
       " ['2', 'to', 'to', 'ADP', 'TO', '_', '1', 'fixed', '_', 'TokenRange=10:12'],\n",
       " ['3',\n",
       "  'Taiwan',\n",
       "  'Taiwan',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '10',\n",
       "  'nmod:poss',\n",
       "  '_',\n",
       "  'TokenRange=13:19'],\n",
       " ['4', '’s', '’s', 'PART', 'POS', '_', '3', 'case', '_', 'TokenRange=20:22'],\n",
       " ['5', '“', '“', 'PUNCT', '``', '_', '10', 'punct', '_', 'TokenRange=23:24'],\n",
       " ['6',\n",
       "  'Ministry',\n",
       "  'Ministry',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '10',\n",
       "  'dep',\n",
       "  '_',\n",
       "  'TokenRange=25:33'],\n",
       " ['7', 'of', 'of', 'ADP', 'IN', '_', '8', 'case', '_', 'TokenRange=34:36'],\n",
       " ['8',\n",
       "  'Economy',\n",
       "  'Economy',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '6',\n",
       "  'obl',\n",
       "  '_',\n",
       "  'TokenRange=37:44'],\n",
       " ['9', '“', '“', 'PUNCT', '``', '_', '10', 'punct', '_', 'TokenRange=45:46'],\n",
       " ['10',\n",
       "  'statistics',\n",
       "  'statistics',\n",
       "  'NOUN',\n",
       "  'NNS',\n",
       "  '_',\n",
       "  '26',\n",
       "  'obl',\n",
       "  '_',\n",
       "  'TokenRange=47:57'],\n",
       " ['11', ',', ',', 'PUNCT', ',', '_', '26', 'punct', '_', 'TokenRange=58:59'],\n",
       " ['12', 'the', 'the', 'DET', 'DT', '_', '13', 'det', '_', 'TokenRange=60:63'],\n",
       " ['13',\n",
       "  'volume',\n",
       "  'volume',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '26',\n",
       "  'nsubj',\n",
       "  '_',\n",
       "  'TokenRange=64:70'],\n",
       " ['14', 'of', 'of', 'ADP', 'IN', '_', '15', 'case', '_', 'TokenRange=71:73'],\n",
       " ['15',\n",
       "  'trade',\n",
       "  'trade',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '13',\n",
       "  'nmod',\n",
       "  '_',\n",
       "  'TokenRange=74:79'],\n",
       " ['16',\n",
       "  'between',\n",
       "  'between',\n",
       "  'ADP',\n",
       "  'IN',\n",
       "  '_',\n",
       "  '17',\n",
       "  'case',\n",
       "  '_',\n",
       "  'TokenRange=80:87'],\n",
       " ['17',\n",
       "  'mainland',\n",
       "  'mainland',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '15',\n",
       "  'nmod',\n",
       "  '_',\n",
       "  'TokenRange=88:96'],\n",
       " ['18', 'and', 'and', 'CONJ', 'CC', '_', '19', 'cc', '_', 'TokenRange=97:100'],\n",
       " ['19',\n",
       "  'Taiwan',\n",
       "  'Taiwan',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '17',\n",
       "  'conj',\n",
       "  '_',\n",
       "  'TokenRange=101:107'],\n",
       " ['20',\n",
       "  'last',\n",
       "  'last',\n",
       "  'ADJ',\n",
       "  'JJ',\n",
       "  '_',\n",
       "  '21',\n",
       "  'amod',\n",
       "  '_',\n",
       "  'TokenRange=108:112'],\n",
       " ['21',\n",
       "  'year',\n",
       "  'year',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '26',\n",
       "  'obl:tmod',\n",
       "  '_',\n",
       "  'TokenRange=113:117'],\n",
       " ['22',\n",
       "  'was',\n",
       "  'be',\n",
       "  'VERB',\n",
       "  'VBD',\n",
       "  '_',\n",
       "  '26',\n",
       "  'cop',\n",
       "  '_',\n",
       "  'TokenRange=118:121'],\n",
       " ['23',\n",
       "  '20.9',\n",
       "  '20.9',\n",
       "  'NUM',\n",
       "  'CD',\n",
       "  '_',\n",
       "  '24',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=122:126'],\n",
       " ['24',\n",
       "  'billion',\n",
       "  'billion',\n",
       "  'NUM',\n",
       "  'CD',\n",
       "  '_',\n",
       "  '26',\n",
       "  'nummod',\n",
       "  '_',\n",
       "  'TokenRange=127:134'],\n",
       " ['25',\n",
       "  'US',\n",
       "  'US',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '26',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=135:137'],\n",
       " ['26',\n",
       "  'dollars',\n",
       "  'dollar',\n",
       "  'NOUN',\n",
       "  'NNS',\n",
       "  '_',\n",
       "  '0',\n",
       "  'root',\n",
       "  '_',\n",
       "  'TokenRange=138:145'],\n",
       " ['27', '.', '.', 'PUNCT', '.', '_', '26', 'punct', '_', 'TokenRange=146:147']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'xinhua'\n",
    "framework = 'amr'\n",
    "dataset2cid2parse[dataset][framework2dataset2mrp_jsons[framework][dataset][1]['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'nw.chtb_0012.2',\n",
       " 'flavor': 2,\n",
       " 'framework': 'amr',\n",
       " 'version': 0.9,\n",
       " 'time': '2019-04-10 (20:11)',\n",
       " 'input': 'According to Taiwan \\'s \" Ministry of Economy \" statistics , the volume of trade between mainland and Taiwan last year was 20.9 billion US dollars .',\n",
       " 'tops': [0],\n",
       " 'nodes': [{'id': 0, 'label': 'say-01'},\n",
       "  {'id': 1, 'label': 'statistic'},\n",
       "  {'id': 2, 'label': 'government-organization'},\n",
       "  {'id': 3,\n",
       "   'label': 'name',\n",
       "   'properties': ['op1', 'op2', 'op3'],\n",
       "   'values': ['Ministry', 'of', 'Economy']},\n",
       "  {'id': 4,\n",
       "   'label': 'monetary-quantity',\n",
       "   'properties': ['quant'],\n",
       "   'values': ['20900000000']},\n",
       "  {'id': 5, 'label': 'dollar'},\n",
       "  {'id': 6, 'label': 'country'},\n",
       "  {'id': 7, 'label': 'name', 'properties': ['op1'], 'values': ['US']},\n",
       "  {'id': 8, 'label': 'volume'},\n",
       "  {'id': 9, 'label': 'trade-01'},\n",
       "  {'id': 10, 'label': 'mainland'},\n",
       "  {'id': 11, 'label': 'country'},\n",
       "  {'id': 12, 'label': 'name', 'properties': ['op1'], 'values': ['Taiwan']},\n",
       "  {'id': 13, 'label': 'year'},\n",
       "  {'id': 14, 'label': 'last'}],\n",
       " 'edges': [{'source': 1, 'target': 2, 'label': 'source'},\n",
       "  {'source': 11, 'target': 12, 'label': 'name'},\n",
       "  {'source': 2, 'target': 3, 'label': 'name'},\n",
       "  {'source': 13, 'target': 14, 'label': 'mod', 'normal': 'domain'},\n",
       "  {'source': 9, 'target': 10, 'label': 'ARG0'},\n",
       "  {'source': 4, 'target': 5, 'label': 'unit'},\n",
       "  {'source': 0, 'target': 4, 'label': 'ARG1'},\n",
       "  {'source': 5, 'target': 6, 'label': 'mod', 'normal': 'domain'},\n",
       "  {'source': 6, 'target': 7, 'label': 'name'},\n",
       "  {'source': 8, 'target': 13, 'label': 'time'},\n",
       "  {'source': 0, 'target': 1, 'label': 'ARG0'},\n",
       "  {'source': 2, 'target': 11, 'label': 'poss'},\n",
       "  {'source': 8, 'target': 9, 'label': 'quant-of', 'normal': 'quant'},\n",
       "  {'source': 4, 'target': 8, 'label': 'domain'},\n",
       "  {'source': 9, 'target': 11, 'label': 'ARG2'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons[framework][dataset][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrp",
   "language": "python",
   "name": "mrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
