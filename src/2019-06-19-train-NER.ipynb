{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    USING_IPYTHON = True\n",
    "except NameError:\n",
    "    USING_IPYTHON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('mrp_data_dir', help='')\n",
    "ap.add_argument('--train-sub-dir', default='training', help='')\n",
    "ap.add_argument('--companion-sub-dir', default='./mrp-companion/2019/companion')\n",
    "ap.add_argument('--mrp-file-extension', default='.mrp')\n",
    "ap.add_argument('--companion-file-extension', default='.conllu')\n",
    "ap.add_argument('--graphviz-file-template', default='http://localhost:8000/files/proj29_ds1/home/slai/mrp/graphviz/{}/{}.mrp/{}.png')\n",
    "arg_string = \"\"\"\n",
    "    ./data/\n",
    "\"\"\"\n",
    "arguments = [arg for arg_line in arg_string.split(r'\\\\n') for arg in arg_line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    args = ap.parse_args(arguments)\n",
    "else:\n",
    "    args = ap.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(companion_file_extension='.conllu', companion_sub_dir='./mrp-companion/2019/companion', graphviz_file_template='http://localhost:8000/files/proj29_ds1/home/slai/mrp/graphviz/{}/{}.mrp/{}.png', mrp_data_dir='./data/', mrp_file_extension='.mrp', train_sub_dir='training')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ipython notebook specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    # matplotlib config\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKWOWN = 'UNKWOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ucca', 'psd', 'eds', 'dm', 'amr']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(args.mrp_data_dir, args.train_sub_dir)\n",
    "frameworks = [sub_dir for sub_dir in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, sub_dir))]\n",
    "frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frameworks:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "dataset_name:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  50%|█████     | 1/2 [00:00<00:00,  2.37it/s]\u001b[A\n",
      "frameworks:  20%|██        | 1/5 [00:00<00:03,  1.02it/s]s]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  40%|████      | 2/5 [00:05<00:06,  2.05s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  60%|██████    | 3/5 [00:11<00:06,  3.26s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  80%|████████  | 4/5 [00:18<00:04,  4.22s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  21%|██▏       | 3/14 [00:00<00:00, 23.38it/s]\u001b[A\n",
      "dataset_name:  43%|████▎     | 6/14 [00:00<00:00, 15.21it/s]\u001b[A\n",
      "dataset_name:  57%|█████▋    | 8/14 [00:00<00:00, 11.23it/s]\u001b[A\n",
      "dataset_name:  71%|███████▏  | 10/14 [00:01<00:00,  5.06it/s]\u001b[A\n",
      "dataset_name:  79%|███████▊  | 11/14 [00:01<00:00,  4.59it/s]\u001b[A\n",
      "dataset_name:  93%|█████████▎| 13/14 [00:02<00:00,  5.72it/s]\u001b[A\n",
      "frameworks: 100%|██████████| 5/5 [00:20<00:00,  3.60s/it]t/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons = {}\n",
    "for framework in tqdm(frameworks, desc='frameworks'):\n",
    "    dataset2mrp_jsons = {}\n",
    "    framework_dir = os.path.join(train_dir, framework)\n",
    "    dataset_names = os.listdir(framework_dir)\n",
    "    \n",
    "    for dataset_name in tqdm(dataset_names, desc='dataset_name'):\n",
    "        mrp_jsons = []\n",
    "        if not dataset_name.endswith(args.mrp_file_extension):\n",
    "            continue\n",
    "        with open(os.path.join(framework_dir, dataset_name)) as rf:\n",
    "            for line in rf:\n",
    "                mrp_json = json.loads(line.strip())\n",
    "                if framework == 'ucca' and 'nodes' in mrp_json and 'input' in mrp_json:\n",
    "                    input_text = mrp_json['input']\n",
    "                    nodes = mrp_json['nodes']\n",
    "                    for i, node in enumerate(nodes):\n",
    "                        if 'anchors' not in node:\n",
    "                            continue\n",
    "                        text_segments = []\n",
    "                        for anchor in node['anchors']:\n",
    "                            text_segments.append(input_text[anchor.get('from', -1): anchor.get('to', -1)])\n",
    "                        mrp_json['nodes'][i]['label'] = ''.join(text_segments)\n",
    "                        \n",
    "                mrp_jsons.append(mrp_json)\n",
    "        dataset_name = dataset_name.split('.')[0]\n",
    "        dataset2mrp_jsons[dataset_name] = mrp_jsons\n",
    "                \n",
    "    framework2dataset2mrp_jsons[framework] = dataset2mrp_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:ucca\n",
      "INFO:__main__:['wiki', 'ewt']\n",
      "INFO:__main__:psd\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:eds\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:dm\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:amr\n",
      "INFO:__main__:['xinhua', 'wsj', 'wiki', 'wb', 'rte', 'proxy', 'mt09sdl', 'lorelei', 'fables', 'dfb', 'dfa', 'cctv', 'bolt', 'amr-guidelines']\n"
     ]
    }
   ],
   "source": [
    "for framework in framework2dataset2mrp_jsons:\n",
    "    logger.info(framework)\n",
    "    logger.info(list(framework2dataset2mrp_jsons[framework].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing companion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset: 100%|██████████| 13/13 [00:04<00:00,  2.73it/s]\n",
      "dataset: 100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\n",
      "dataset: 100%|██████████| 6/6 [00:00<00:00, 18.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset2cid2parse = {}\n",
    "for framework in os.listdir(args.companion_sub_dir):\n",
    "    framework_dir = os.path.join(args.companion_sub_dir, framework)\n",
    "    if not os.path.isdir(framework_dir):\n",
    "        continue\n",
    "    for dataset in tqdm(os.listdir(framework_dir), desc='dataset'):\n",
    "        if not dataset.endswith(args.companion_file_extension):\n",
    "            continue\n",
    "        dataset_name = dataset.split('.')[0].rstrip(string.digits)\n",
    "        cid2parse = {}\n",
    "        with open(os.path.join(framework_dir, dataset)) as rf:\n",
    "            parse = []\n",
    "            for line in rf:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    cid2parse[cid] = parse\n",
    "                    parse = []\n",
    "                    cid = ''\n",
    "                elif line.startswith('#'):\n",
    "                    cid = line[1:]\n",
    "                else:\n",
    "                    parse.append(line.split('\\t'))\n",
    "        dataset2cid2parse[dataset_name] = cid2parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['amr-guidelines', 'bolt', 'cctv', 'dfa', 'dfb', 'fables', 'lorelei', 'mt09sdl', 'proxy', 'rte', 'wb', 'wiki', 'xinhua', 'wsj', 'ewt'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2cid2parse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'20003001' in dataset2cid2parse['wsj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20003001'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons[framework][dataset][2]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,\n",
       " 'The monthly sales have been setting records every month since March .',\n",
       " [['1', 'The', 'the', 'DET', 'DT', '_', '3', 'det', '_', 'TokenRange=0:3'],\n",
       "  ['2',\n",
       "   'monthly',\n",
       "   'monthly',\n",
       "   'ADJ',\n",
       "   'JJ',\n",
       "   '_',\n",
       "   '3',\n",
       "   'amod',\n",
       "   '_',\n",
       "   'TokenRange=4:11'],\n",
       "  ['3',\n",
       "   'sales',\n",
       "   'sale',\n",
       "   'NOUN',\n",
       "   'NNS',\n",
       "   '_',\n",
       "   '6',\n",
       "   'nsubj',\n",
       "   '_',\n",
       "   'TokenRange=12:17'],\n",
       "  ['4',\n",
       "   'have',\n",
       "   'have',\n",
       "   'AUX',\n",
       "   'VBP',\n",
       "   '_',\n",
       "   '6',\n",
       "   'aux',\n",
       "   '_',\n",
       "   'TokenRange=18:22'],\n",
       "  ['5', 'been', 'be', 'AUX', 'VBN', '_', '6', 'aux', '_', 'TokenRange=23:27'],\n",
       "  ['6',\n",
       "   'setting',\n",
       "   'set',\n",
       "   'VERB',\n",
       "   'VBG',\n",
       "   '_',\n",
       "   '0',\n",
       "   'root',\n",
       "   '_',\n",
       "   'TokenRange=28:35'],\n",
       "  ['7',\n",
       "   'records',\n",
       "   'record',\n",
       "   'NOUN',\n",
       "   'NNS',\n",
       "   '_',\n",
       "   '6',\n",
       "   'obj',\n",
       "   '_',\n",
       "   'TokenRange=36:43'],\n",
       "  ['8',\n",
       "   'every',\n",
       "   'every',\n",
       "   'DET',\n",
       "   'DT',\n",
       "   '_',\n",
       "   '9',\n",
       "   'det',\n",
       "   '_',\n",
       "   'TokenRange=44:49'],\n",
       "  ['9',\n",
       "   'month',\n",
       "   'month',\n",
       "   'NOUN',\n",
       "   'NN',\n",
       "   '_',\n",
       "   '6',\n",
       "   'obl:tmod',\n",
       "   '_',\n",
       "   'TokenRange=50:55'],\n",
       "  ['10',\n",
       "   'since',\n",
       "   'since',\n",
       "   'ADP',\n",
       "   'IN',\n",
       "   '_',\n",
       "   '11',\n",
       "   'case',\n",
       "   '_',\n",
       "   'TokenRange=56:61'],\n",
       "  ['11',\n",
       "   'March',\n",
       "   'March',\n",
       "   'PROPN',\n",
       "   'NNP',\n",
       "   '_',\n",
       "   '6',\n",
       "   'obl',\n",
       "   '_',\n",
       "   'TokenRange=62:67'],\n",
       "  ['12', '.', '.', 'PUNCT', '.', '_', '6', 'punct', '_', 'TokenRange=67:68']])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'wsj'\n",
    "framework = 'dm'\n",
    "mrp_index = 128\n",
    "parse = None\n",
    "while not parse:\n",
    "    mrp_index += 1\n",
    "    cid = framework2dataset2mrp_jsons[framework][dataset][mrp_index]['id']\n",
    "    parse = dataset2cid2parse[dataset].get(cid)\n",
    "    \n",
    "(mrp_index, ' '.join([word_record[1] for word_record in parse]), parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20016003'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework2dataset2mrp_jsons[framework][dataset][mrp_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the monthly sale set record every month since March\n",
      "http://localhost:8000/tree/proj29_ds1/home/slai/mrp/graphviz/dm/wsj.mrp/20016003.png\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([\n",
    "    node.get('label', '') \n",
    "    for node in sorted(framework2dataset2mrp_jsons[framework][dataset][mrp_index]['nodes'], key=lambda x:x['id'])\n",
    "]))\n",
    "print('http://localhost:8000/tree/proj29_ds1/home/slai/mrp/graphviz/{}/{}.mrp/{}.png'.format(framework, dataset, cid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate NER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xinhua'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = list(dataset2cid2parse[dataset])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'Xinhua',\n",
       "  'Xinhua',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '3',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=0:6'],\n",
       " ['2',\n",
       "  'News',\n",
       "  'News',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '3',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=7:11'],\n",
       " ['3',\n",
       "  'Agency',\n",
       "  'Agency',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '0',\n",
       "  'root',\n",
       "  '_',\n",
       "  'TokenRange=12:18'],\n",
       " ['4', ',', ',', 'PUNCT', ',', '_', '3', 'punct', '_', 'TokenRange=19:20'],\n",
       " ['5',\n",
       "  'Hong',\n",
       "  'Hong',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '6',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=21:25'],\n",
       " ['6',\n",
       "  'Kong',\n",
       "  'Kong',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '3',\n",
       "  'appos',\n",
       "  '_',\n",
       "  'TokenRange=26:30'],\n",
       " ['7', ',', ',', 'PUNCT', ',', '_', '3', 'punct', '_', 'TokenRange=31:32'],\n",
       " ['8',\n",
       "  'February',\n",
       "  'February',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '9',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=33:41'],\n",
       " ['9',\n",
       "  '23rd',\n",
       "  '23rd',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '3',\n",
       "  'appos',\n",
       "  '_',\n",
       "  'TokenRange=42:46']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2cid2parse[dataset][cid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-19-fbca15c464ac>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-fbca15c464ac>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for dataset, cid2parse in dataset2cid2parse.items():\n",
    "    for cid, parse in cid2parse.items():\n",
    "        for word_record in parse:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
