{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    USING_IPYTHON = True\n",
    "except NameError:\n",
    "    USING_IPYTHON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('mrp_data_dir', help='')\n",
    "ap.add_argument('--train-sub-dir', default='training', help='')\n",
    "ap.add_argument('--companion-sub-dir', default='./mrp-companion/2019/companion')\n",
    "ap.add_argument('--mrp-file-extension', default='.mrp')\n",
    "ap.add_argument('--companion-file-extension', default='.conllu')\n",
    "arg_string = \"\"\"\n",
    "    ./data/\n",
    "\"\"\"\n",
    "arguments = [arg for arg_line in arg_string.split(r'\\\\n') for arg in arg_line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    args = ap.parse_args(arguments)\n",
    "else:\n",
    "    args = ap.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(companion_file_extension='.conllu', companion_sub_dir='./mrp-companion/2019/companion', mrp_data_dir='./data/', mrp_file_extension='.mrp', train_sub_dir='training')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ipython notebook specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USING_IPYTHON:\n",
    "    # matplotlib config\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKWOWN = 'UNKWOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ucca', 'psd', 'eds', 'dm', 'amr']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(args.mrp_data_dir, args.train_sub_dir)\n",
    "frameworks = [sub_dir for sub_dir in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, sub_dir))]\n",
    "frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frameworks:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "dataset_name:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  50%|█████     | 1/2 [00:00<00:00,  4.06it/s]\u001b[A\n",
      "frameworks:  20%|██        | 1/5 [00:00<00:01,  2.27it/s]s]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  40%|████      | 2/5 [00:07<00:07,  2.36s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  60%|██████    | 3/5 [00:11<00:05,  2.90s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "frameworks:  80%|████████  | 4/5 [00:16<00:03,  3.47s/it]t]\u001b[A\n",
      "dataset_name:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "dataset_name:  43%|████▎     | 6/14 [00:00<00:00, 21.92it/s]\u001b[A\n",
      "dataset_name:  57%|█████▋    | 8/14 [00:00<00:00, 18.67it/s]\u001b[A\n",
      "dataset_name:  71%|███████▏  | 10/14 [00:02<00:01,  2.37it/s]\u001b[A\n",
      "dataset_name:  79%|███████▊  | 11/14 [00:03<00:01,  2.81it/s]\u001b[A\n",
      "frameworks: 100%|██████████| 5/5 [00:19<00:00,  3.40s/it]t/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons = {}\n",
    "for framework in tqdm(frameworks, desc='frameworks'):\n",
    "    dataset2mrp_jsons = {}\n",
    "    framework_dir = os.path.join(train_dir, framework)\n",
    "    dataset_names = os.listdir(framework_dir)\n",
    "    \n",
    "    for dataset_name in tqdm(dataset_names, desc='dataset_name'):\n",
    "        mrp_jsons = []\n",
    "        if not dataset_name.endswith(args.mrp_file_extension):\n",
    "            continue\n",
    "        with open(os.path.join(framework_dir, dataset_name)) as rf:\n",
    "            for line in rf:\n",
    "                mrp_json = json.loads(line.strip())\n",
    "                if framework == 'ucca' and 'nodes' in mrp_json and 'input' in mrp_json:\n",
    "                    input_text = mrp_json['input']\n",
    "                    nodes = mrp_json['nodes']\n",
    "                    for i, node in enumerate(nodes):\n",
    "                        if 'anchors' not in node:\n",
    "                            continue\n",
    "                        text_segments = []\n",
    "                        for anchor in node['anchors']:\n",
    "                            text_segments.append(input_text[anchor.get('from', -1): anchor.get('to', -1)])\n",
    "                        mrp_json['nodes'][i]['label'] = ''.join(text_segments)\n",
    "                        \n",
    "                mrp_jsons.append(mrp_json)\n",
    "        dataset_name = dataset_name.split('.')[0]\n",
    "        dataset2mrp_jsons[dataset_name] = mrp_jsons\n",
    "                \n",
    "    framework2dataset2mrp_jsons[framework] = dataset2mrp_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:ucca\n",
      "INFO:__main__:['wiki', 'ewt']\n",
      "INFO:__main__:psd\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:eds\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:dm\n",
      "INFO:__main__:['wsj']\n",
      "INFO:__main__:amr\n",
      "INFO:__main__:['xinhua', 'wsj', 'wiki', 'wb', 'rte', 'proxy', 'mt09sdl', 'lorelei', 'fables', 'dfb', 'dfa', 'cctv', 'bolt', 'amr-guidelines']\n"
     ]
    }
   ],
   "source": [
    "for framework in framework2dataset2mrp_jsons:\n",
    "    logger.info(framework)\n",
    "    logger.info(list(framework2dataset2mrp_jsons[framework].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing companion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset: 100%|██████████| 13/13 [00:06<00:00,  1.49it/s]\n",
      "dataset: 100%|██████████| 5/5 [00:01<00:00,  3.91it/s]\n",
      "dataset: 100%|██████████| 6/6 [00:00<00:00, 23.34it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset2cid2parse = {}\n",
    "for framework in os.listdir(args.companion_sub_dir):\n",
    "    framework_dir = os.path.join(args.companion_sub_dir, framework)\n",
    "    if not os.path.isdir(framework_dir):\n",
    "        continue\n",
    "    for dataset in tqdm(os.listdir(framework_dir), desc='dataset'):\n",
    "        if not dataset.endswith(args.companion_file_extension):\n",
    "            continue\n",
    "        dataset_name = dataset.split('.')[0].rstrip(string.digits)\n",
    "        cid2parse = {}\n",
    "        with open(os.path.join(framework_dir, dataset)) as rf:\n",
    "            parse = []\n",
    "            for line in rf:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    cid2parse[cid] = parse\n",
    "                    parse = []\n",
    "                    cid = ''\n",
    "                elif line.startswith('#'):\n",
    "                    cid = line[1:]\n",
    "                else:\n",
    "                    parse.append(line.split('\\t'))\n",
    "        dataset2cid2parse[dataset_name] = cid2parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['amr-guidelines', 'bolt', 'cctv', 'dfa', 'dfb', 'fables', 'lorelei', 'mt09sdl', 'proxy', 'rte', 'wb', 'wiki', 'xinhua', 'wsj', 'ewt'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2cid2parse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'Both',\n",
       "  'both',\n",
       "  'DET',\n",
       "  'DT',\n",
       "  '_',\n",
       "  '2',\n",
       "  'cc:preconj',\n",
       "  '_',\n",
       "  'TokenRange=0:4'],\n",
       " ['2',\n",
       "  'Depp',\n",
       "  'Depp',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '9',\n",
       "  'nsubj',\n",
       "  '_',\n",
       "  'TokenRange=5:9'],\n",
       " ['3', 'and', 'and', 'CONJ', 'CC', '_', '8', 'cc', '_', 'TokenRange=10:13'],\n",
       " ['4',\n",
       "  'his',\n",
       "  'he',\n",
       "  'PRON',\n",
       "  'PRP$',\n",
       "  '_',\n",
       "  '8',\n",
       "  'nmod:poss',\n",
       "  '_',\n",
       "  'TokenRange=14:17'],\n",
       " ['5',\n",
       "  'subsequent',\n",
       "  'subsequent',\n",
       "  'ADJ',\n",
       "  'JJ',\n",
       "  '_',\n",
       "  '8',\n",
       "  'amod',\n",
       "  '_',\n",
       "  'TokenRange=18:28'],\n",
       " ['6',\n",
       "  'fiancé',\n",
       "  'fiancé',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '8',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=29:35'],\n",
       " ['7',\n",
       "  'Sherilyn',\n",
       "  'Sherilyn',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '8',\n",
       "  'compound',\n",
       "  '_',\n",
       "  'TokenRange=36:44'],\n",
       " ['8',\n",
       "  'Fenn',\n",
       "  'Fenn',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '2',\n",
       "  'conj',\n",
       "  '_',\n",
       "  'TokenRange=45:49'],\n",
       " ['9',\n",
       "  'auditioned',\n",
       "  'audition',\n",
       "  'VERB',\n",
       "  'VBD',\n",
       "  '_',\n",
       "  '0',\n",
       "  'root',\n",
       "  '_',\n",
       "  'TokenRange=50:60'],\n",
       " ['10', 'for', 'for', 'ADP', 'IN', '_', '13', 'case', '_', 'TokenRange=61:64'],\n",
       " ['11', 'the', 'the', 'DET', 'DT', '_', '13', 'det', '_', 'TokenRange=65:68'],\n",
       " ['12',\n",
       "  '1986',\n",
       "  '1986',\n",
       "  'NUM',\n",
       "  'CD',\n",
       "  '_',\n",
       "  '13',\n",
       "  'nummod',\n",
       "  '_',\n",
       "  'TokenRange=69:73'],\n",
       " ['13',\n",
       "  'film',\n",
       "  'film',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '9',\n",
       "  'obl',\n",
       "  '_',\n",
       "  'TokenRange=74:78'],\n",
       " ['14',\n",
       "  'Thrashin',\n",
       "  'Thrashin',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '13',\n",
       "  'dep',\n",
       "  '_',\n",
       "  'TokenRange=79:87'],\n",
       " ['15', '’', '’', 'PUNCT', \"''\", '_', '13', 'punct', '_', 'TokenRange=87:88'],\n",
       " ['16', 'and', 'and', 'CONJ', 'CC', '_', '20', 'cc', '_', 'TokenRange=89:92'],\n",
       " ['17',\n",
       "  'they',\n",
       "  'they',\n",
       "  'PRON',\n",
       "  'PRP',\n",
       "  '_',\n",
       "  '20',\n",
       "  'nsubj:pass',\n",
       "  '_',\n",
       "  'TokenRange=93:97'],\n",
       " ['18',\n",
       "  'were',\n",
       "  'be',\n",
       "  'AUX',\n",
       "  'VBD',\n",
       "  '_',\n",
       "  '20',\n",
       "  'aux:pass',\n",
       "  '_',\n",
       "  'TokenRange=98:102'],\n",
       " ['19',\n",
       "  'both',\n",
       "  'both',\n",
       "  'DET',\n",
       "  'DT',\n",
       "  '_',\n",
       "  '20',\n",
       "  'dep',\n",
       "  '_',\n",
       "  'TokenRange=103:107'],\n",
       " ['20',\n",
       "  'cast',\n",
       "  'cast',\n",
       "  'VERB',\n",
       "  'VBN',\n",
       "  '_',\n",
       "  '9',\n",
       "  'conj',\n",
       "  '_',\n",
       "  'TokenRange=108:112'],\n",
       " ['21', ',', ',', 'PUNCT', ',', '_', '20', 'punct', '_', 'TokenRange=112:113'],\n",
       " ['22',\n",
       "  'with',\n",
       "  'with',\n",
       "  'SCONJ',\n",
       "  'IN',\n",
       "  '_',\n",
       "  '25',\n",
       "  'mark',\n",
       "  '_',\n",
       "  'TokenRange=114:118'],\n",
       " ['23',\n",
       "  'Depp',\n",
       "  'Depp',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '25',\n",
       "  'nsubj:pass',\n",
       "  '_',\n",
       "  'TokenRange=119:123'],\n",
       " ['24',\n",
       "  'being',\n",
       "  'be',\n",
       "  'AUX',\n",
       "  'VBG',\n",
       "  '_',\n",
       "  '25',\n",
       "  'aux:pass',\n",
       "  '_',\n",
       "  'TokenRange=124:129'],\n",
       " ['25',\n",
       "  'chosen',\n",
       "  'choose',\n",
       "  'VERB',\n",
       "  'VBN',\n",
       "  '_',\n",
       "  '20',\n",
       "  'advcl',\n",
       "  '_',\n",
       "  'TokenRange=130:136'],\n",
       " ['26', 'by', 'by', 'ADP', 'IN', '_', '30', 'case', '_', 'TokenRange=137:139'],\n",
       " ['27',\n",
       "  'the',\n",
       "  'the',\n",
       "  'DET',\n",
       "  'DT',\n",
       "  '_',\n",
       "  '28',\n",
       "  'det',\n",
       "  '_',\n",
       "  'TokenRange=140:143'],\n",
       " ['28',\n",
       "  'film',\n",
       "  'film',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '30',\n",
       "  'nmod:poss',\n",
       "  '_',\n",
       "  'TokenRange=144:148'],\n",
       " ['29',\n",
       "  '’s',\n",
       "  '’s',\n",
       "  'PART',\n",
       "  'POS',\n",
       "  '_',\n",
       "  '28',\n",
       "  'case',\n",
       "  '_',\n",
       "  'TokenRange=148:150'],\n",
       " ['30',\n",
       "  'director',\n",
       "  'director',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '25',\n",
       "  'obl',\n",
       "  '_',\n",
       "  'TokenRange=151:159'],\n",
       " ['31',\n",
       "  'to',\n",
       "  'to',\n",
       "  'PART',\n",
       "  'TO',\n",
       "  '_',\n",
       "  '32',\n",
       "  'mark',\n",
       "  '_',\n",
       "  'TokenRange=160:162'],\n",
       " ['32',\n",
       "  'star',\n",
       "  'star',\n",
       "  'VERB',\n",
       "  'VB',\n",
       "  '_',\n",
       "  '25',\n",
       "  'xcomp',\n",
       "  '_',\n",
       "  'TokenRange=163:167'],\n",
       " ['33', 'as', 'as', 'ADP', 'IN', '_', '35', 'case', '_', 'TokenRange=168:170'],\n",
       " ['34',\n",
       "  'the',\n",
       "  'the',\n",
       "  'DET',\n",
       "  'DT',\n",
       "  '_',\n",
       "  '35',\n",
       "  'det',\n",
       "  '_',\n",
       "  'TokenRange=171:174'],\n",
       " ['35',\n",
       "  'lead',\n",
       "  'lead',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '32',\n",
       "  'obl',\n",
       "  '_',\n",
       "  'TokenRange=175:179'],\n",
       " ['36', ',', ',', 'PUNCT', ',', '_', '35', 'punct', '_', 'TokenRange=179:180'],\n",
       " ['37',\n",
       "  'which',\n",
       "  'which',\n",
       "  'PRON',\n",
       "  'WDT',\n",
       "  '_',\n",
       "  '45',\n",
       "  'nsubj',\n",
       "  '_',\n",
       "  'TokenRange=181:186'],\n",
       " ['38',\n",
       "  'would',\n",
       "  'would',\n",
       "  'AUX',\n",
       "  'MD',\n",
       "  '_',\n",
       "  '45',\n",
       "  'aux',\n",
       "  '_',\n",
       "  'TokenRange=187:192'],\n",
       " ['39',\n",
       "  'have',\n",
       "  'have',\n",
       "  'AUX',\n",
       "  'VB',\n",
       "  '_',\n",
       "  '45',\n",
       "  'aux',\n",
       "  '_',\n",
       "  'TokenRange=193:197'],\n",
       " ['40',\n",
       "  'been',\n",
       "  'be',\n",
       "  'VERB',\n",
       "  'VBN',\n",
       "  '_',\n",
       "  '45',\n",
       "  'cop',\n",
       "  '_',\n",
       "  'TokenRange=198:202'],\n",
       " ['41',\n",
       "  'Depp',\n",
       "  'Depp',\n",
       "  'PROPN',\n",
       "  'NNP',\n",
       "  '_',\n",
       "  '45',\n",
       "  'nmod:poss',\n",
       "  '_',\n",
       "  'TokenRange=203:207'],\n",
       " ['42',\n",
       "  '’s',\n",
       "  '’s',\n",
       "  'PART',\n",
       "  'POS',\n",
       "  '_',\n",
       "  '41',\n",
       "  'case',\n",
       "  '_',\n",
       "  'TokenRange=207:209'],\n",
       " ['43',\n",
       "  'second',\n",
       "  'second',\n",
       "  'ADJ',\n",
       "  'JJ',\n",
       "  '_',\n",
       "  '45',\n",
       "  'amod',\n",
       "  '_',\n",
       "  'TokenRange=210:216'],\n",
       " ['44',\n",
       "  'major',\n",
       "  'major',\n",
       "  'ADJ',\n",
       "  'JJ',\n",
       "  '_',\n",
       "  '45',\n",
       "  'amod',\n",
       "  '_',\n",
       "  'TokenRange=217:222'],\n",
       " ['45',\n",
       "  'role',\n",
       "  'role',\n",
       "  'NOUN',\n",
       "  'NN',\n",
       "  '_',\n",
       "  '35',\n",
       "  'acl:relcl',\n",
       "  '_',\n",
       "  'TokenRange=223:227'],\n",
       " ['46', '.', '.', 'PUNCT', '.', '_', '9', 'punct', '_', 'TokenRange=227:228']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2cid2parse['wiki'][framework2dataset2mrp_jsons['ucca']['wiki'][2]['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '586010',\n",
       " 'flavor': 1,\n",
       " 'framework': 'ucca',\n",
       " 'version': 0.9,\n",
       " 'time': '2019-04-11 (22:04)',\n",
       " 'input': \"Both Depp and his subsequent fiancé Sherilyn Fenn auditioned for the 1986 film Thrashin' and they were both cast, with Depp being chosen by the film's director to star as the lead, which would have been Depp's second major role.\",\n",
       " 'tops': [47],\n",
       " 'nodes': [{'id': 0, 'anchors': [{'from': 0, 'to': 4}], 'label': 'Both'},\n",
       "  {'id': 1, 'anchors': [{'from': 5, 'to': 9}], 'label': 'Depp'},\n",
       "  {'id': 2, 'anchors': [{'from': 10, 'to': 13}], 'label': 'and'},\n",
       "  {'id': 3, 'anchors': [{'from': 14, 'to': 17}], 'label': 'his'},\n",
       "  {'id': 4, 'anchors': [{'from': 18, 'to': 28}], 'label': 'subsequent'},\n",
       "  {'id': 5, 'anchors': [{'from': 29, 'to': 35}], 'label': 'fiancé'},\n",
       "  {'id': 6,\n",
       "   'anchors': [{'from': 36, 'to': 44}, {'from': 45, 'to': 49}],\n",
       "   'label': 'SherilynFenn'},\n",
       "  {'id': 7, 'anchors': [{'from': 50, 'to': 60}], 'label': 'auditioned'},\n",
       "  {'id': 8, 'anchors': [{'from': 61, 'to': 64}], 'label': 'for'},\n",
       "  {'id': 9, 'anchors': [{'from': 65, 'to': 68}], 'label': 'the'},\n",
       "  {'id': 10, 'anchors': [{'from': 69, 'to': 73}], 'label': '1986'},\n",
       "  {'id': 11, 'anchors': [{'from': 74, 'to': 78}], 'label': 'film'},\n",
       "  {'id': 12, 'anchors': [{'from': 79, 'to': 87}], 'label': 'Thrashin'},\n",
       "  {'id': 13, 'anchors': [{'from': 87, 'to': 88}], 'label': \"'\"},\n",
       "  {'id': 14, 'anchors': [{'from': 89, 'to': 92}], 'label': 'and'},\n",
       "  {'id': 15, 'anchors': [{'from': 93, 'to': 97}], 'label': 'they'},\n",
       "  {'id': 16, 'anchors': [{'from': 98, 'to': 102}], 'label': 'were'},\n",
       "  {'id': 17, 'anchors': [{'from': 103, 'to': 107}], 'label': 'both'},\n",
       "  {'id': 18, 'anchors': [{'from': 108, 'to': 112}], 'label': 'cast'},\n",
       "  {'id': 19, 'anchors': [{'from': 112, 'to': 113}], 'label': ','},\n",
       "  {'id': 20, 'anchors': [{'from': 114, 'to': 118}], 'label': 'with'},\n",
       "  {'id': 21, 'anchors': [{'from': 119, 'to': 123}], 'label': 'Depp'},\n",
       "  {'id': 22, 'anchors': [{'from': 124, 'to': 129}], 'label': 'being'},\n",
       "  {'id': 23, 'anchors': [{'from': 130, 'to': 136}], 'label': 'chosen'},\n",
       "  {'id': 24, 'anchors': [{'from': 137, 'to': 139}], 'label': 'by'},\n",
       "  {'id': 25, 'anchors': [{'from': 140, 'to': 143}], 'label': 'the'},\n",
       "  {'id': 26, 'anchors': [{'from': 144, 'to': 148}], 'label': 'film'},\n",
       "  {'id': 27, 'anchors': [{'from': 148, 'to': 150}], 'label': \"'s\"},\n",
       "  {'id': 28, 'anchors': [{'from': 151, 'to': 159}], 'label': 'director'},\n",
       "  {'id': 29, 'anchors': [{'from': 160, 'to': 162}], 'label': 'to'},\n",
       "  {'id': 30, 'anchors': [{'from': 163, 'to': 167}], 'label': 'star'},\n",
       "  {'id': 31, 'anchors': [{'from': 168, 'to': 170}], 'label': 'as'},\n",
       "  {'id': 32, 'anchors': [{'from': 171, 'to': 174}], 'label': 'the'},\n",
       "  {'id': 33, 'anchors': [{'from': 175, 'to': 179}], 'label': 'lead'},\n",
       "  {'id': 34, 'anchors': [{'from': 179, 'to': 180}], 'label': ','},\n",
       "  {'id': 35, 'anchors': [{'from': 181, 'to': 186}], 'label': 'which'},\n",
       "  {'id': 36, 'anchors': [{'from': 187, 'to': 192}], 'label': 'would'},\n",
       "  {'id': 37, 'anchors': [{'from': 193, 'to': 197}], 'label': 'have'},\n",
       "  {'id': 38, 'anchors': [{'from': 198, 'to': 202}], 'label': 'been'},\n",
       "  {'id': 39, 'anchors': [{'from': 203, 'to': 207}], 'label': 'Depp'},\n",
       "  {'id': 40, 'anchors': [{'from': 207, 'to': 209}], 'label': \"'s\"},\n",
       "  {'id': 41, 'anchors': [{'from': 210, 'to': 216}], 'label': 'second'},\n",
       "  {'id': 42, 'anchors': [{'from': 217, 'to': 222}], 'label': 'major'},\n",
       "  {'id': 43, 'anchors': [{'from': 223, 'to': 227}], 'label': 'role'},\n",
       "  {'id': 44, 'anchors': [{'from': 227, 'to': 228}], 'label': '.'},\n",
       "  {'id': 45},\n",
       "  {'id': 46},\n",
       "  {'id': 47},\n",
       "  {'id': 48},\n",
       "  {'id': 49},\n",
       "  {'id': 50},\n",
       "  {'id': 51},\n",
       "  {'id': 52},\n",
       "  {'id': 53},\n",
       "  {'id': 54},\n",
       "  {'id': 55},\n",
       "  {'id': 56},\n",
       "  {'id': 57},\n",
       "  {'id': 58},\n",
       "  {'id': 59},\n",
       "  {'id': 60},\n",
       "  {'id': 61},\n",
       "  {'id': 62},\n",
       "  {'id': 63},\n",
       "  {'id': 64}],\n",
       " 'edges': [{'source': 63, 'target': 62, 'label': 'E'},\n",
       "  {'source': 59, 'target': 29, 'label': 'F'},\n",
       "  {'source': 58, 'target': 26, 'label': 'C'},\n",
       "  {'source': 55, 'target': 18, 'label': 'P'},\n",
       "  {'source': 59, 'target': 30, 'label': 'P'},\n",
       "  {'source': 55, 'target': 16, 'label': 'F'},\n",
       "  {'source': 63, 'target': 64, 'label': 'E'},\n",
       "  {'source': 63, 'target': 43, 'label': 'C'},\n",
       "  {'source': 52, 'target': 11, 'label': 'C'},\n",
       "  {'source': 56, 'target': 22, 'label': 'F'},\n",
       "  {'source': 57, 'target': 24, 'label': 'R'},\n",
       "  {'source': 49, 'target': 3, 'label': 'A'},\n",
       "  {'source': 62,\n",
       "   'target': 43,\n",
       "   'label': 'A',\n",
       "   'properties': ['remote'],\n",
       "   'values': [True]},\n",
       "  {'source': 47, 'target': 19, 'label': 'U'},\n",
       "  {'source': 61,\n",
       "   'target': 33,\n",
       "   'label': 'A',\n",
       "   'properties': ['remote'],\n",
       "   'values': [True]},\n",
       "  {'source': 61, 'target': 63, 'label': 'A'},\n",
       "  {'source': 51, 'target': 12, 'label': 'C'},\n",
       "  {'source': 50, 'target': 6, 'label': 'C'},\n",
       "  {'source': 45, 'target': 48, 'label': 'C'},\n",
       "  {'source': 53, 'target': 10, 'label': 'T'},\n",
       "  {'source': 61, 'target': 35, 'label': 'R'},\n",
       "  {'source': 47, 'target': 14, 'label': 'L'},\n",
       "  {'source': 61, 'target': 36, 'label': 'D'},\n",
       "  {'source': 50, 'target': 49, 'label': 'E'},\n",
       "  {'source': 49, 'target': 4, 'label': 'D'},\n",
       "  {'source': 57, 'target': 58, 'label': 'A'},\n",
       "  {'source': 63, 'target': 41, 'label': 'Q'},\n",
       "  {'source': 63, 'target': 44, 'label': 'U'},\n",
       "  {'source': 54, 'target': 17, 'label': 'Q'},\n",
       "  {'source': 54, 'target': 15, 'label': 'C'},\n",
       "  {'source': 46, 'target': 45, 'label': 'A'},\n",
       "  {'source': 59,\n",
       "   'target': 21,\n",
       "   'label': 'A',\n",
       "   'properties': ['remote'],\n",
       "   'values': [True]},\n",
       "  {'source': 53,\n",
       "   'target': 11,\n",
       "   'label': 'A',\n",
       "   'properties': ['remote'],\n",
       "   'values': [True]},\n",
       "  {'source': 49, 'target': 5, 'label': 'A'},\n",
       "  {'source': 51, 'target': 52, 'label': 'E'},\n",
       "  {'source': 47, 'target': 13, 'label': 'U'},\n",
       "  {'source': 57, 'target': 28, 'label': 'P'},\n",
       "  {'source': 60, 'target': 61, 'label': 'E'},\n",
       "  {'source': 56, 'target': 57, 'label': 'A'},\n",
       "  {'source': 57, 'target': 28, 'label': 'A'},\n",
       "  {'source': 60, 'target': 34, 'label': 'U'},\n",
       "  {'source': 56, 'target': 59, 'label': 'A'},\n",
       "  {'source': 51, 'target': 8, 'label': 'R'},\n",
       "  {'source': 62, 'target': 39, 'label': 'A'},\n",
       "  {'source': 49, 'target': 5, 'label': 'S'},\n",
       "  {'source': 55, 'target': 54, 'label': 'A'},\n",
       "  {'source': 52, 'target': 9, 'label': 'E'},\n",
       "  {'source': 46, 'target': 51, 'label': 'A'},\n",
       "  {'source': 64,\n",
       "   'target': 43,\n",
       "   'label': 'A',\n",
       "   'properties': ['remote'],\n",
       "   'values': [True]},\n",
       "  {'source': 60, 'target': 31, 'label': 'R'},\n",
       "  {'source': 62, 'target': 40, 'label': 'S'},\n",
       "  {'source': 59, 'target': 60, 'label': 'A'},\n",
       "  {'source': 58, 'target': 27, 'label': 'R'},\n",
       "  {'source': 48, 'target': 50, 'label': 'C'},\n",
       "  {'source': 47, 'target': 46, 'label': 'H'},\n",
       "  {'source': 61, 'target': 37, 'label': 'F'},\n",
       "  {'source': 64, 'target': 42, 'label': 'S'},\n",
       "  {'source': 48, 'target': 2, 'label': 'N'},\n",
       "  {'source': 56, 'target': 23, 'label': 'P'},\n",
       "  {'source': 56, 'target': 21, 'label': 'A'},\n",
       "  {'source': 60, 'target': 32, 'label': 'E'},\n",
       "  {'source': 61, 'target': 38, 'label': 'S'},\n",
       "  {'source': 52, 'target': 53, 'label': 'E'},\n",
       "  {'source': 48, 'target': 1, 'label': 'C'},\n",
       "  {'source': 47, 'target': 20, 'label': 'L'},\n",
       "  {'source': 60, 'target': 33, 'label': 'C'},\n",
       "  {'source': 47, 'target': 55, 'label': 'H'},\n",
       "  {'source': 47, 'target': 56, 'label': 'H'},\n",
       "  {'source': 57, 'target': 25, 'label': 'F'},\n",
       "  {'source': 45, 'target': 0, 'label': 'Q'},\n",
       "  {'source': 46, 'target': 7, 'label': 'P'}]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework2dataset2mrp_jsons['ucca']['wiki'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
